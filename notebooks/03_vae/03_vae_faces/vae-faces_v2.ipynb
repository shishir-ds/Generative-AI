{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ¤ª Variational Autoencoders - CelebA Faces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we'll walk through the steps required to train your own variational autoencoder on the CelebA faces dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T08:05:34.067774Z",
     "iopub.status.busy": "2023-06-14T08:05:34.067464Z",
     "iopub.status.idle": "2023-06-14T08:05:34.083036Z",
     "shell.execute_reply": "2023-06-14T08:05:34.082115Z",
     "shell.execute_reply.started": "2023-06-14T08:05:34.067748Z"
    }
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.getcwd()\n",
    "# os.chdir('/kaggle/input/requirements-file/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-13T19:49:21.981481Z",
     "iopub.status.busy": "2023-06-13T19:49:21.981027Z",
     "iopub.status.idle": "2023-06-13T19:49:39.064370Z",
     "shell.execute_reply": "2023-06-13T19:49:39.062990Z",
     "shell.execute_reply.started": "2023-06-13T19:49:21.981446Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install -r '/kaggle/input/requirements-file-1/requirements.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib.metadata import version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T15:41:46.252380Z",
     "iopub.status.busy": "2023-06-14T15:41:46.251961Z",
     "iopub.status.idle": "2023-06-14T15:41:46.268529Z",
     "shell.execute_reply": "2023-06-14T15:41:46.266877Z",
     "shell.execute_reply.started": "2023-06-14T15:41:46.252353Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def sample_batch(dataset):\n",
    "    batch = dataset.take(1).get_single_element()\n",
    "    if isinstance(batch, tuple):\n",
    "        batch = batch[0]\n",
    "    return batch.numpy()\n",
    "\n",
    "\n",
    "def display(\n",
    "    images, n=10, size=(20, 100), cmap=\"gray_r\", as_type=\"float32\", save_to=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Displays n random images from each one of the supplied arrays.\n",
    "    \"\"\"\n",
    "    if images.max() > 1.0:\n",
    "        images = images / 255.0\n",
    "    elif images.min() < 0.0:\n",
    "        images = (images + 1.0) / 2.0\n",
    "\n",
    "    plt.figure(figsize=size)\n",
    "    for i in range(n):\n",
    "        _ = plt.subplot(1, n, i + 1)\n",
    "        plt.imshow(images[i].astype(as_type), cmap=cmap)\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    if save_to:\n",
    "        plt.savefig(save_to)\n",
    "        print(f\"\\nSaved to {save_to}\")\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T15:41:46.273747Z",
     "iopub.status.busy": "2023-06-14T15:41:46.273449Z",
     "iopub.status.idle": "2023-06-14T15:41:46.299612Z",
     "shell.execute_reply": "2023-06-14T15:41:46.298296Z",
     "shell.execute_reply.started": "2023-06-14T15:41:46.273703Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def get_vector_from_label(data, vae, embedding_dim, label):\n",
    "    current_sum_POS = np.zeros(shape=embedding_dim, dtype=\"float32\")\n",
    "    current_n_POS = 0\n",
    "    current_mean_POS = np.zeros(shape=embedding_dim, dtype=\"float32\")\n",
    "\n",
    "    current_sum_NEG = np.zeros(shape=embedding_dim, dtype=\"float32\")\n",
    "    current_n_NEG = 0\n",
    "    current_mean_NEG = np.zeros(shape=embedding_dim, dtype=\"float32\")\n",
    "\n",
    "    current_vector = np.zeros(shape=embedding_dim, dtype=\"float32\")\n",
    "    current_dist = 0\n",
    "\n",
    "    print(\"label: \" + label)\n",
    "    print(\"images : POS move : NEG move :distance : Ã°Ââ€ºÂ¥ distance\")\n",
    "    while current_n_POS < 10000:\n",
    "        batch = list(data.take(1).get_single_element())\n",
    "        im = batch[0]\n",
    "        attribute = batch[1]\n",
    "\n",
    "        _, _, z = vae.encoder.predict(np.array(im), verbose=0)\n",
    "\n",
    "        z_POS = z[attribute == 1]\n",
    "        z_NEG = z[attribute == -1]\n",
    "\n",
    "        if len(z_POS) > 0:\n",
    "            current_sum_POS = current_sum_POS + np.sum(z_POS, axis=0)\n",
    "            current_n_POS += len(z_POS)\n",
    "            new_mean_POS = current_sum_POS / current_n_POS\n",
    "            movement_POS = np.linalg.norm(new_mean_POS - current_mean_POS)\n",
    "\n",
    "        if len(z_NEG) > 0:\n",
    "            current_sum_NEG = current_sum_NEG + np.sum(z_NEG, axis=0)\n",
    "            current_n_NEG += len(z_NEG)\n",
    "            new_mean_NEG = current_sum_NEG / current_n_NEG\n",
    "            movement_NEG = np.linalg.norm(new_mean_NEG - current_mean_NEG)\n",
    "\n",
    "        current_vector = new_mean_POS - new_mean_NEG\n",
    "        new_dist = np.linalg.norm(current_vector)\n",
    "        dist_change = new_dist - current_dist\n",
    "\n",
    "        print(\n",
    "            str(current_n_POS)\n",
    "            + \"    : \"\n",
    "            + str(np.round(movement_POS, 3))\n",
    "            + \"    : \"\n",
    "            + str(np.round(movement_NEG, 3))\n",
    "            + \"    : \"\n",
    "            + str(np.round(new_dist, 3))\n",
    "            + \"    : \"\n",
    "            + str(np.round(dist_change, 3))\n",
    "        )\n",
    "\n",
    "        current_mean_POS = np.copy(new_mean_POS)\n",
    "        current_mean_NEG = np.copy(new_mean_NEG)\n",
    "        current_dist = np.copy(new_dist)\n",
    "\n",
    "        if np.sum([movement_POS, movement_NEG]) < 0.08:\n",
    "            current_vector = current_vector / current_dist\n",
    "            print(\"Found the \" + label + \" vector\")\n",
    "            break\n",
    "\n",
    "    return current_vector\n",
    "\n",
    "\n",
    "def add_vector_to_images(data, vae, feature_vec):\n",
    "    n_to_show = 5\n",
    "    factors = [-4, -3, -2, -1, 0, 1, 2, 3, 4]\n",
    "\n",
    "    example_batch = list(data.take(1).get_single_element())\n",
    "    example_images = example_batch[0]\n",
    "\n",
    "    _, _, z_points = vae.encoder.predict(example_images, verbose=0)\n",
    "\n",
    "    fig = plt.figure(figsize=(18, 10))\n",
    "\n",
    "    counter = 1\n",
    "\n",
    "    for i in range(n_to_show):\n",
    "        img = example_images[i]\n",
    "        sub = fig.add_subplot(n_to_show, len(factors) + 1, counter)\n",
    "        sub.axis(\"off\")\n",
    "        sub.imshow(img)\n",
    "\n",
    "        counter += 1\n",
    "\n",
    "        for factor in factors:\n",
    "            changed_z_point = z_points[i] + feature_vec * factor\n",
    "            changed_image = vae.decoder.predict(\n",
    "                np.array([changed_z_point]), verbose=0\n",
    "            )[0]\n",
    "\n",
    "            sub = fig.add_subplot(n_to_show, len(factors) + 1, counter)\n",
    "            sub.axis(\"off\")\n",
    "            sub.imshow(changed_image)\n",
    "\n",
    "            counter += 1\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def morph_faces(data, vae):\n",
    "    factors = np.arange(0, 1, 0.1)\n",
    "\n",
    "    example_batch = list(data.take(1).get_single_element())[:2]\n",
    "    example_images = example_batch[0]\n",
    "    _, _, z_points = vae.encoder.predict(example_images, verbose=0)\n",
    "\n",
    "    fig = plt.figure(figsize=(18, 8))\n",
    "\n",
    "    counter = 1\n",
    "\n",
    "    img = example_images[0]\n",
    "    sub = fig.add_subplot(1, len(factors) + 2, counter)\n",
    "    sub.axis(\"off\")\n",
    "    sub.imshow(img)\n",
    "\n",
    "    counter += 1\n",
    "\n",
    "    for factor in factors:\n",
    "        changed_z_point = z_points[0] * (1 - factor) + z_points[1] * factor\n",
    "        changed_image = vae.decoder.predict(\n",
    "            np.array([changed_z_point]), verbose=0\n",
    "        )[0]\n",
    "        sub = fig.add_subplot(1, len(factors) + 2, counter)\n",
    "        sub.axis(\"off\")\n",
    "        sub.imshow(changed_image)\n",
    "\n",
    "        counter += 1\n",
    "\n",
    "    img = example_images[1]\n",
    "    sub = fig.add_subplot(1, len(factors) + 2, counter)\n",
    "    sub.axis(\"off\")\n",
    "    sub.imshow(img)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T15:41:46.301559Z",
     "iopub.status.busy": "2023-06-14T15:41:46.301212Z",
     "iopub.status.idle": "2023-06-14T15:42:02.412358Z",
     "shell.execute_reply": "2023-06-14T15:42:02.411446Z",
     "shell.execute_reply.started": "2023-06-14T15:41:46.301527Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mK\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     10\u001b[0m     layers,\n\u001b[0;32m     11\u001b[0m     models,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     16\u001b[0m     optimizers,\n\u001b[0;32m     17\u001b[0m )\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.keras'"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import (\n",
    "    layers,\n",
    "    models,\n",
    "    callbacks,\n",
    "    utils,\n",
    "    metrics,\n",
    "    losses,\n",
    "    optimizers,\n",
    ")\n",
    "\n",
    "# from scipy.stats import norm\n",
    "# import pandas as pd\n",
    "\n",
    "# # from kaggle.input.utils-file.utils import sample_batch, display\n",
    "\n",
    "# # from vae_utils import get_vector_from_label, add_vector_to_images, morph_faces\n",
    "\n",
    "# from notebooks.utils import sample_batch, display\n",
    "\n",
    "# from vae_utils import get_vector_from_label, add_vector_to_images, morph_faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "PackageNotFoundError",
     "evalue": "tensorflow",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPackageNotFoundError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mversion\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtensorflow\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\anaconda3\\envs\\gen_ai\\lib\\importlib\\metadata.py:530\u001b[0m, in \u001b[0;36mversion\u001b[1;34m(distribution_name)\u001b[0m\n\u001b[0;32m    523\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mversion\u001b[39m(distribution_name):\n\u001b[0;32m    524\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get the version string for the named package.\u001b[39;00m\n\u001b[0;32m    525\u001b[0m \n\u001b[0;32m    526\u001b[0m \u001b[38;5;124;03m    :param distribution_name: The name of the distribution package to query.\u001b[39;00m\n\u001b[0;32m    527\u001b[0m \u001b[38;5;124;03m    :return: The version string for the package as defined in the package's\u001b[39;00m\n\u001b[0;32m    528\u001b[0m \u001b[38;5;124;03m        \"Version\" metadata key.\u001b[39;00m\n\u001b[0;32m    529\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdistribution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdistribution_name\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mversion\n",
      "File \u001b[1;32mC:\\anaconda3\\envs\\gen_ai\\lib\\importlib\\metadata.py:503\u001b[0m, in \u001b[0;36mdistribution\u001b[1;34m(distribution_name)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdistribution\u001b[39m(distribution_name):\n\u001b[0;32m    498\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get the ``Distribution`` instance for the named package.\u001b[39;00m\n\u001b[0;32m    499\u001b[0m \n\u001b[0;32m    500\u001b[0m \u001b[38;5;124;03m    :param distribution_name: The name of the distribution package as a string.\u001b[39;00m\n\u001b[0;32m    501\u001b[0m \u001b[38;5;124;03m    :return: A ``Distribution`` instance (or subclass thereof).\u001b[39;00m\n\u001b[0;32m    502\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 503\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDistribution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdistribution_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\anaconda3\\envs\\gen_ai\\lib\\importlib\\metadata.py:177\u001b[0m, in \u001b[0;36mDistribution.from_name\u001b[1;34m(cls, name)\u001b[0m\n\u001b[0;32m    175\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m dist\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 177\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PackageNotFoundError(name)\n",
      "\u001b[1;31mPackageNotFoundError\u001b[0m: tensorflow"
     ]
    }
   ],
   "source": [
    "version('tensorflow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Parameters <a name=\"parameters\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T16:34:54.363885Z",
     "iopub.status.busy": "2023-06-14T16:34:54.363479Z",
     "iopub.status.idle": "2023-06-14T16:34:54.440773Z",
     "shell.execute_reply": "2023-06-14T16:34:54.439875Z",
     "shell.execute_reply.started": "2023-06-14T16:34:54.363852Z"
    }
   },
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 64\n",
    "CHANNELS = 3\n",
    "BATCH_SIZE = 128\n",
    "NUM_FEATURES = 64\n",
    "Z_DIM = 250\n",
    "LEARNING_RATE = 0.0005\n",
    "EPOCHS = 5\n",
    "BETA = 2000\n",
    "LOAD_MODEL = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare the data <a name=\"prepare\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T16:35:08.937455Z",
     "iopub.status.busy": "2023-06-14T16:35:08.937096Z",
     "iopub.status.idle": "2023-06-14T16:39:58.646850Z",
     "shell.execute_reply": "2023-06-14T16:39:58.645758Z",
     "shell.execute_reply.started": "2023-06-14T16:35:08.937420Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "train_data = utils.image_dataset_from_directory(\n",
    "    \"/kaggle/input/celeba-dataset/img_align_celeba\",\n",
    "    labels=None,\n",
    "    color_mode=\"rgb\",\n",
    "    image_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    interpolation=\"bilinear\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T16:39:58.649544Z",
     "iopub.status.busy": "2023-06-14T16:39:58.648700Z",
     "iopub.status.idle": "2023-06-14T16:39:58.772778Z",
     "shell.execute_reply": "2023-06-14T16:39:58.771887Z",
     "shell.execute_reply.started": "2023-06-14T16:39:58.649508Z"
    }
   },
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "def preprocess(img):\n",
    "    img = tf.cast(img, \"float32\") / 255.0\n",
    "    return img\n",
    "\n",
    "\n",
    "train = train_data.map(lambda x: preprocess(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T16:39:58.774240Z",
     "iopub.status.busy": "2023-06-14T16:39:58.773910Z",
     "iopub.status.idle": "2023-06-14T16:39:59.855783Z",
     "shell.execute_reply": "2023-06-14T16:39:59.854785Z",
     "shell.execute_reply.started": "2023-06-14T16:39:58.774207Z"
    }
   },
   "outputs": [],
   "source": [
    "train_sample = sample_batch(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T16:39:59.860698Z",
     "iopub.status.busy": "2023-06-14T16:39:59.860357Z",
     "iopub.status.idle": "2023-06-14T16:40:00.453586Z",
     "shell.execute_reply": "2023-06-14T16:40:00.452635Z",
     "shell.execute_reply.started": "2023-06-14T16:39:59.860669Z"
    }
   },
   "outputs": [],
   "source": [
    "# Show some faces from the training set\n",
    "display(train_sample, cmap=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Build the variational autoencoder <a name=\"build\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T16:40:00.455960Z",
     "iopub.status.busy": "2023-06-14T16:40:00.455296Z",
     "iopub.status.idle": "2023-06-14T16:40:00.532816Z",
     "shell.execute_reply": "2023-06-14T16:40:00.531967Z",
     "shell.execute_reply.started": "2023-06-14T16:40:00.455925Z"
    }
   },
   "outputs": [],
   "source": [
    "class Sampling(layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = K.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T16:40:00.534529Z",
     "iopub.status.busy": "2023-06-14T16:40:00.534112Z",
     "iopub.status.idle": "2023-06-14T16:40:00.615519Z",
     "shell.execute_reply": "2023-06-14T16:40:00.614605Z",
     "shell.execute_reply.started": "2023-06-14T16:40:00.534491Z"
    }
   },
   "outputs": [],
   "source": [
    "def encoder_module(IMAGE_SIZE=IMAGE_SIZE,NUM_FEATURES=NUM_FEATURES,Z_DIM=Z_DIM,strides=2,num_layers=5):\n",
    "    \n",
    "    # Encoder\n",
    "    encoder_input = layers.Input(\n",
    "        shape=(IMAGE_SIZE, IMAGE_SIZE, CHANNELS), name=\"encoder_input\"\n",
    "    )\n",
    "    x = layers.Conv2D(64, kernel_size=3, strides=2, padding=\"valid\")(\n",
    "        encoder_input\n",
    "    )\n",
    "    \n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "    \n",
    "    for i in range(num_layers):\n",
    "        \n",
    "\n",
    "        x = layers.Conv2D(NUM_FEATURES, kernel_size=3, strides=2, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.LeakyReLU()(x)\n",
    "       \n",
    "    shape_before_flattening = K.int_shape(x)[1:]  # the decoder will need this!\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "    z_mean = layers.Dense(Z_DIM, name=\"z_mean\")(x)\n",
    "    z_log_var = layers.Dense(Z_DIM, name=\"z_log_var\")(x)\n",
    "    z = Sampling()([z_mean, z_log_var])\n",
    "\n",
    "    encoder = models.Model(encoder_input, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "    print(encoder.summary())\n",
    "    return encoder,shape_before_flattening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T16:40:00.618589Z",
     "iopub.status.busy": "2023-06-14T16:40:00.617646Z",
     "iopub.status.idle": "2023-06-14T16:40:00.694833Z",
     "shell.execute_reply": "2023-06-14T16:40:00.694009Z",
     "shell.execute_reply.started": "2023-06-14T16:40:00.618554Z"
    }
   },
   "outputs": [],
   "source": [
    "def decoder_module(shape_before_flattening,Z_DIM=Z_DIM,NUM_FEATURES=NUM_FEATURES,num_layers=5):\n",
    "    # Decoder\n",
    "    decoder_input = layers.Input(shape=(Z_DIM,), name=\"decoder_input\")\n",
    "    x = layers.Dense(np.prod(shape_before_flattening))(decoder_input)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "    x = layers.Reshape(shape_before_flattening)(x)\n",
    "   \n",
    "    for i in range(num_layers):\n",
    "        if i<num_layers-1:\n",
    "            \n",
    "            x = layers.Conv2DTranspose(\n",
    "                NUM_FEATURES, kernel_size=3, strides=2, padding=\"same\"\n",
    "            )(x)\n",
    "            x = layers.BatchNormalization()(x)\n",
    "            x = layers.LeakyReLU()(x)\n",
    "        else:\n",
    "            x = layers.Conv2DTranspose(\n",
    "                32, kernel_size=3, strides=2, padding=\"same\"\n",
    "            )(x)\n",
    "            x = layers.BatchNormalization()(x)\n",
    "            x = layers.LeakyReLU()(x)\n",
    "            \n",
    "   \n",
    "   \n",
    "    decoder_output = layers.Conv2DTranspose(\n",
    "        CHANNELS, kernel_size=3, strides=2, activation=\"sigmoid\", padding=\"same\"\n",
    "    )(x)\n",
    "    decoder = models.Model(decoder_input, decoder_output)\n",
    "    print(decoder.summary())\n",
    "    return decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T16:40:00.696846Z",
     "iopub.status.busy": "2023-06-14T16:40:00.696005Z",
     "iopub.status.idle": "2023-06-14T16:40:00.778977Z",
     "shell.execute_reply": "2023-06-14T16:40:00.778016Z",
     "shell.execute_reply.started": "2023-06-14T16:40:00.696812Z"
    }
   },
   "outputs": [],
   "source": [
    "class VAE(models.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.total_loss_tracker = metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"Call the model on a particular input.\"\"\"\n",
    "        z_mean, z_log_var, z = encoder(inputs)\n",
    "        reconstruction = decoder(z)\n",
    "        return z_mean, z_log_var, reconstruction\n",
    "\n",
    "    def train_step(self, data):\n",
    "        \"\"\"Step run during training.\"\"\"\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, reconstruction = self(data, training=True)\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                BETA * losses.mean_squared_error(data, reconstruction)\n",
    "            )\n",
    "            kl_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                    -0.5\n",
    "                    * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)),\n",
    "                    axis=1,\n",
    "                )\n",
    "            )\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }\n",
    "\n",
    "    def test_step(self, data):\n",
    "        \"\"\"Step run during validation.\"\"\"\n",
    "        if isinstance(data, tuple):\n",
    "            data = data[0]\n",
    "\n",
    "        z_mean, z_log_var, reconstruction = self(data)\n",
    "        reconstruction_loss = tf.reduce_mean(\n",
    "            BETA * losses.mean_squared_error(data, reconstruction)\n",
    "        )\n",
    "        kl_loss = tf.reduce_mean(\n",
    "            tf.reduce_sum(\n",
    "                -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)),\n",
    "                axis=1,\n",
    "            )\n",
    "        )\n",
    "        total_loss = reconstruction_loss + kl_loss\n",
    "\n",
    "        return {\n",
    "            \"loss\": total_loss,\n",
    "            \"reconstruction_loss\": reconstruction_loss,\n",
    "            \"kl_loss\": kl_loss,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T16:40:00.781612Z",
     "iopub.status.busy": "2023-06-14T16:40:00.780825Z",
     "iopub.status.idle": "2023-06-14T16:40:01.072212Z",
     "shell.execute_reply": "2023-06-14T16:40:01.071488Z",
     "shell.execute_reply.started": "2023-06-14T16:40:00.781579Z"
    }
   },
   "outputs": [],
   "source": [
    "encoder,shape_before_flattening=encoder_module(NUM_FEATURES=128,Z_DIM=250,strides=1,num_layers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T16:40:01.076277Z",
     "iopub.status.busy": "2023-06-14T16:40:01.075928Z",
     "iopub.status.idle": "2023-06-14T16:40:01.587314Z",
     "shell.execute_reply": "2023-06-14T16:40:01.586590Z",
     "shell.execute_reply.started": "2023-06-14T16:40:01.076244Z"
    }
   },
   "outputs": [],
   "source": [
    "decoder=decoder_module(shape_before_flattening,Z_DIM=250,NUM_FEATURES=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T16:40:01.588625Z",
     "iopub.status.busy": "2023-06-14T16:40:01.588311Z",
     "iopub.status.idle": "2023-06-14T16:40:01.792685Z",
     "shell.execute_reply": "2023-06-14T16:40:01.791842Z",
     "shell.execute_reply.started": "2023-06-14T16:40:01.588596Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a variational autoencoder\n",
    "vae = VAE(encoder, decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train the variational autoencoder <a name=\"train\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T16:40:01.798958Z",
     "iopub.status.busy": "2023-06-14T16:40:01.796833Z",
     "iopub.status.idle": "2023-06-14T16:40:01.906410Z",
     "shell.execute_reply": "2023-06-14T16:40:01.905598Z",
     "shell.execute_reply.started": "2023-06-14T16:40:01.798921Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compile the variational autoencoder\n",
    "optimizer = optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "vae.compile(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T16:40:01.908049Z",
     "iopub.status.busy": "2023-06-14T16:40:01.907538Z",
     "iopub.status.idle": "2023-06-14T16:40:02.008074Z",
     "shell.execute_reply": "2023-06-14T16:40:02.007312Z",
     "shell.execute_reply.started": "2023-06-14T16:40:01.908013Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a model save checkpoint\n",
    "model_checkpoint_callback = callbacks.ModelCheckpoint(\n",
    "    filepath=\"./checkpoint\",\n",
    "    save_weights_only=False,\n",
    "    save_freq=\"epoch\",\n",
    "    monitor=\"loss\",\n",
    "    mode=\"min\",\n",
    "    save_best_only=True,\n",
    "    verbose=0,\n",
    ")\n",
    "\n",
    "tensorboard_callback = callbacks.TensorBoard(log_dir=\"./logs\")\n",
    "\n",
    "\n",
    "class ImageGenerator(callbacks.Callback):\n",
    "    def __init__(self, num_img, latent_dim):\n",
    "        self.num_img = num_img\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        random_latent_vectors = tf.random.normal(\n",
    "            shape=(self.num_img, self.latent_dim)\n",
    "        )\n",
    "        generated_images = self.model.decoder(random_latent_vectors)\n",
    "        generated_images *= 255\n",
    "        generated_images.numpy()\n",
    "        for i in range(self.num_img):\n",
    "            img = utils.array_to_img(generated_images[i])\n",
    "            img.save(\"/kaggle/working/output/generated_img_%03d_%d.png\" % (epoch, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T16:40:02.010257Z",
     "iopub.status.busy": "2023-06-14T16:40:02.009504Z",
     "iopub.status.idle": "2023-06-14T16:40:02.105772Z",
     "shell.execute_reply": "2023-06-14T16:40:02.105013Z",
     "shell.execute_reply.started": "2023-06-14T16:40:02.010212Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/kaggle/working/output/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T16:44:49.529422Z",
     "iopub.status.busy": "2023-06-14T16:44:49.528756Z",
     "iopub.status.idle": "2023-06-14T16:44:50.639070Z",
     "shell.execute_reply": "2023-06-14T16:44:50.637775Z",
     "shell.execute_reply.started": "2023-06-14T16:44:49.529387Z"
    }
   },
   "outputs": [],
   "source": [
    "!mkdir output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T16:40:02.212319Z",
     "iopub.status.busy": "2023-06-14T16:40:02.211392Z",
     "iopub.status.idle": "2023-06-14T16:40:02.306492Z",
     "shell.execute_reply": "2023-06-14T16:40:02.305762Z",
     "shell.execute_reply.started": "2023-06-14T16:40:02.212285Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Load old weights if required\n",
    "if LOAD_MODEL:\n",
    "    vae.load_weights(\"./models/vae\")\n",
    "    tmp = vae.predict(train.take(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T16:45:41.811011Z",
     "iopub.status.busy": "2023-06-14T16:45:41.809865Z",
     "iopub.status.idle": "2023-06-14T17:13:35.610160Z",
     "shell.execute_reply": "2023-06-14T17:13:35.609275Z",
     "shell.execute_reply.started": "2023-06-14T16:45:41.810958Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "vae.fit(\n",
    "    train,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[\n",
    "        model_checkpoint_callback,\n",
    "        tensorboard_callback,\n",
    "        ImageGenerator(num_img=10, latent_dim=Z_DIM),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T17:17:19.328200Z",
     "iopub.status.busy": "2023-06-14T17:17:19.327831Z",
     "iopub.status.idle": "2023-06-14T17:17:33.613216Z",
     "shell.execute_reply": "2023-06-14T17:17:33.612287Z",
     "shell.execute_reply.started": "2023-06-14T17:17:19.328171Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save the final models\n",
    "vae.save(\"./models/vae\")\n",
    "encoder.save(\"./models/encoder\")\n",
    "decoder.save(\"./models/decoder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Reconstruct using the variational autoencoder <a name=\"reconstruct\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T17:18:21.917463Z",
     "iopub.status.busy": "2023-06-14T17:18:21.916826Z",
     "iopub.status.idle": "2023-06-14T17:18:23.718526Z",
     "shell.execute_reply": "2023-06-14T17:18:23.717548Z",
     "shell.execute_reply.started": "2023-06-14T17:18:21.917427Z"
    }
   },
   "outputs": [],
   "source": [
    "# Select a subset of the test set\n",
    "batches_to_predict = 1\n",
    "example_images = np.array(\n",
    "    list(train.take(batches_to_predict).get_single_element())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T17:18:24.612262Z",
     "iopub.status.busy": "2023-06-14T17:18:24.611911Z",
     "iopub.status.idle": "2023-06-14T17:18:26.832956Z",
     "shell.execute_reply": "2023-06-14T17:18:26.831919Z",
     "shell.execute_reply.started": "2023-06-14T17:18:24.612233Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create autoencoder predictions and display\n",
    "z_mean, z_log_var, reconstructions = vae.predict(example_images)\n",
    "print(\"Example real faces\")\n",
    "display(example_images)\n",
    "print(\"Reconstructions\")\n",
    "display(reconstructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Latent space distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T17:18:26.835954Z",
     "iopub.status.busy": "2023-06-14T17:18:26.834970Z",
     "iopub.status.idle": "2023-06-14T17:18:31.023705Z",
     "shell.execute_reply": "2023-06-14T17:18:31.022709Z",
     "shell.execute_reply.started": "2023-06-14T17:18:26.835918Z"
    }
   },
   "outputs": [],
   "source": [
    "_, _, z = vae.encoder.predict(example_images)\n",
    "\n",
    "x = np.linspace(-3, 3, 100)\n",
    "\n",
    "fig = plt.figure(figsize=(20, 5))\n",
    "fig.subplots_adjust(hspace=0.6, wspace=0.4)\n",
    "\n",
    "for i in range(50):\n",
    "    ax = fig.add_subplot(5, 10, i + 1)\n",
    "    ax.hist(z[:, i], density=True, bins=20)\n",
    "    ax.axis(\"off\")\n",
    "    ax.text(\n",
    "        0.5, -0.35, str(i), fontsize=10, ha=\"center\", transform=ax.transAxes\n",
    "    )\n",
    "    ax.plot(x, norm.pdf(x))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Generate new faces <a name=\"decode\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T17:18:31.034020Z",
     "iopub.status.busy": "2023-06-14T17:18:31.030782Z",
     "iopub.status.idle": "2023-06-14T17:18:31.139394Z",
     "shell.execute_reply": "2023-06-14T17:18:31.138164Z",
     "shell.execute_reply.started": "2023-06-14T17:18:31.033980Z"
    }
   },
   "outputs": [],
   "source": [
    "# Sample some points in the latent space, from the standard normal distribution\n",
    "grid_width, grid_height = (10, 3)\n",
    "z_sample = np.random.normal(size=(grid_width * grid_height, Z_DIM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T17:18:31.141925Z",
     "iopub.status.busy": "2023-06-14T17:18:31.141226Z",
     "iopub.status.idle": "2023-06-14T17:18:31.965684Z",
     "shell.execute_reply": "2023-06-14T17:18:31.964719Z",
     "shell.execute_reply.started": "2023-06-14T17:18:31.141885Z"
    }
   },
   "outputs": [],
   "source": [
    "# Decode the sampled points\n",
    "reconstructions = decoder.predict(z_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T17:18:31.968860Z",
     "iopub.status.busy": "2023-06-14T17:18:31.968267Z",
     "iopub.status.idle": "2023-06-14T17:18:33.362815Z",
     "shell.execute_reply": "2023-06-14T17:18:33.361710Z",
     "shell.execute_reply.started": "2023-06-14T17:18:31.968823Z"
    }
   },
   "outputs": [],
   "source": [
    "# Draw a plot of decoded images\n",
    "fig = plt.figure(figsize=(18, 5))\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "# Output the grid of faces\n",
    "for i in range(grid_width * grid_height):\n",
    "    ax = fig.add_subplot(grid_height, grid_width, i + 1)\n",
    "    ax.axis(\"off\")\n",
    "    ax.imshow(reconstructions[i, :, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Manipulate the images <a name=\"manipulate\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T17:18:33.365543Z",
     "iopub.status.busy": "2023-06-14T17:18:33.364501Z",
     "iopub.status.idle": "2023-06-14T17:18:34.648826Z",
     "shell.execute_reply": "2023-06-14T17:18:34.647802Z",
     "shell.execute_reply.started": "2023-06-14T17:18:33.365505Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the label dataset\n",
    "attributes = pd.read_csv(\"/kaggle/input/celeba-dataset/list_attr_celeba.csv\")\n",
    "print(attributes.columns)\n",
    "attributes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T17:18:34.650564Z",
     "iopub.status.busy": "2023-06-14T17:18:34.650130Z",
     "iopub.status.idle": "2023-06-14T17:26:02.703691Z",
     "shell.execute_reply": "2023-06-14T17:26:02.702764Z",
     "shell.execute_reply.started": "2023-06-14T17:18:34.650531Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the face data with label attached\n",
    "LABEL = \"Blond_Hair\"  # <- Set this label\n",
    "labelled_test = utils.image_dataset_from_directory(\n",
    "    \"/kaggle/input/celeba-dataset/img_align_celeba\",\n",
    "    labels=attributes[LABEL].tolist(),\n",
    "    color_mode=\"rgb\",\n",
    "    image_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    interpolation=\"bilinear\",\n",
    ")\n",
    "\n",
    "labelled = labelled_test.map(lambda x, y: (preprocess(x), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T18:07:13.465798Z",
     "iopub.status.busy": "2023-06-14T18:07:13.465388Z",
     "iopub.status.idle": "2023-06-14T18:07:13.549882Z",
     "shell.execute_reply": "2023-06-14T18:07:13.548915Z",
     "shell.execute_reply.started": "2023-06-14T18:07:13.465764Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T18:08:59.087639Z",
     "iopub.status.busy": "2023-06-14T18:08:59.087256Z",
     "iopub.status.idle": "2023-06-14T18:08:59.167812Z",
     "shell.execute_reply": "2023-06-14T18:08:59.166699Z",
     "shell.execute_reply.started": "2023-06-14T18:08:59.087610Z"
    }
   },
   "outputs": [],
   "source": [
    "LABEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T18:08:49.955523Z",
     "iopub.status.busy": "2023-06-14T18:08:49.955139Z",
     "iopub.status.idle": "2023-06-14T18:08:50.032697Z",
     "shell.execute_reply": "2023-06-14T18:08:50.031783Z",
     "shell.execute_reply.started": "2023-06-14T18:08:49.955494Z"
    }
   },
   "outputs": [],
   "source": [
    "# labelled\n",
    "# list(labelled.take(1).get_single_element())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T17:26:52.202917Z",
     "iopub.status.busy": "2023-06-14T17:26:52.202148Z",
     "iopub.status.idle": "2023-06-14T17:28:02.543477Z",
     "shell.execute_reply": "2023-06-14T17:28:02.542407Z",
     "shell.execute_reply.started": "2023-06-14T17:26:52.202875Z"
    }
   },
   "outputs": [],
   "source": [
    "# Find the attribute vector\n",
    "attribute_vec = get_vector_from_label(labelled, vae, Z_DIM, LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T17:28:02.545360Z",
     "iopub.status.busy": "2023-06-14T17:28:02.545014Z",
     "iopub.status.idle": "2023-06-14T17:28:08.396803Z",
     "shell.execute_reply": "2023-06-14T17:28:08.395963Z",
     "shell.execute_reply.started": "2023-06-14T17:28:02.545327Z"
    }
   },
   "outputs": [],
   "source": [
    "# Add vector to images\n",
    "add_vector_to_images(labelled, vae, attribute_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T17:28:08.405920Z",
     "iopub.status.busy": "2023-06-14T17:28:08.398186Z",
     "iopub.status.idle": "2023-06-14T17:28:08.484926Z",
     "shell.execute_reply": "2023-06-14T17:28:08.483771Z",
     "shell.execute_reply.started": "2023-06-14T17:28:08.405882Z"
    }
   },
   "outputs": [],
   "source": [
    "morph_faces(labelled, vae)add_vector_to_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
