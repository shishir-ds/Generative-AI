{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# ðŸ¤ª Variational Autoencoders - CelebA Faces","metadata":{}},{"cell_type":"markdown","source":"In this notebook, we'll walk through the steps required to train your own variational autoencoder on the CelebA faces dataset","metadata":{}},{"cell_type":"code","source":"import os\nos.getcwd()\nos.chdir('/kaggle/input/requirements-file/')","metadata":{"execution":{"iopub.status.busy":"2023-06-14T08:05:34.067464Z","iopub.execute_input":"2023-06-14T08:05:34.067774Z","iopub.status.idle":"2023-06-14T08:05:34.083036Z","shell.execute_reply.started":"2023-06-14T08:05:34.067748Z","shell.execute_reply":"2023-06-14T08:05:34.082115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -r '/kaggle/input/requirements-file-1/requirements.txt'","metadata":{"execution":{"iopub.status.busy":"2023-06-13T19:49:21.981027Z","iopub.execute_input":"2023-06-13T19:49:21.981481Z","iopub.status.idle":"2023-06-13T19:49:39.064370Z","shell.execute_reply.started":"2023-06-13T19:49:21.981446Z","shell.execute_reply":"2023-06-13T19:49:39.062990Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n\ndef sample_batch(dataset):\n    batch = dataset.take(1).get_single_element()\n    if isinstance(batch, tuple):\n        batch = batch[0]\n    return batch.numpy()\n\n\ndef display(\n    images, n=10, size=(20, 100), cmap=\"gray_r\", as_type=\"float32\", save_to=None\n):\n    \"\"\"\n    Displays n random images from each one of the supplied arrays.\n    \"\"\"\n    if images.max() > 1.0:\n        images = images / 255.0\n    elif images.min() < 0.0:\n        images = (images + 1.0) / 2.0\n\n    plt.figure(figsize=size)\n    for i in range(n):\n        _ = plt.subplot(1, n, i + 1)\n        plt.imshow(images[i].astype(as_type), cmap=cmap)\n        plt.axis(\"off\")\n\n    if save_to:\n        plt.savefig(save_to)\n        print(f\"\\nSaved to {save_to}\")\n\n    plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-06-14T15:41:46.251961Z","iopub.execute_input":"2023-06-14T15:41:46.252380Z","iopub.status.idle":"2023-06-14T15:41:46.268529Z","shell.execute_reply.started":"2023-06-14T15:41:46.252353Z","shell.execute_reply":"2023-06-14T15:41:46.266877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\n\n\ndef get_vector_from_label(data, vae, embedding_dim, label):\n    current_sum_POS = np.zeros(shape=embedding_dim, dtype=\"float32\")\n    current_n_POS = 0\n    current_mean_POS = np.zeros(shape=embedding_dim, dtype=\"float32\")\n\n    current_sum_NEG = np.zeros(shape=embedding_dim, dtype=\"float32\")\n    current_n_NEG = 0\n    current_mean_NEG = np.zeros(shape=embedding_dim, dtype=\"float32\")\n\n    current_vector = np.zeros(shape=embedding_dim, dtype=\"float32\")\n    current_dist = 0\n\n    print(\"label: \" + label)\n    print(\"images : POS move : NEG move :distance : Ã°Ââ€ºÂ¥ distance\")\n    while current_n_POS < 10000:\n        batch = list(data.take(1).get_single_element())\n        im = batch[0]\n        attribute = batch[1]\n\n        _, _, z = vae.encoder.predict(np.array(im), verbose=0)\n\n        z_POS = z[attribute == 1]\n        z_NEG = z[attribute == -1]\n\n        if len(z_POS) > 0:\n            current_sum_POS = current_sum_POS + np.sum(z_POS, axis=0)\n            current_n_POS += len(z_POS)\n            new_mean_POS = current_sum_POS / current_n_POS\n            movement_POS = np.linalg.norm(new_mean_POS - current_mean_POS)\n\n        if len(z_NEG) > 0:\n            current_sum_NEG = current_sum_NEG + np.sum(z_NEG, axis=0)\n            current_n_NEG += len(z_NEG)\n            new_mean_NEG = current_sum_NEG / current_n_NEG\n            movement_NEG = np.linalg.norm(new_mean_NEG - current_mean_NEG)\n\n        current_vector = new_mean_POS - new_mean_NEG\n        new_dist = np.linalg.norm(current_vector)\n        dist_change = new_dist - current_dist\n\n        print(\n            str(current_n_POS)\n            + \"    : \"\n            + str(np.round(movement_POS, 3))\n            + \"    : \"\n            + str(np.round(movement_NEG, 3))\n            + \"    : \"\n            + str(np.round(new_dist, 3))\n            + \"    : \"\n            + str(np.round(dist_change, 3))\n        )\n\n        current_mean_POS = np.copy(new_mean_POS)\n        current_mean_NEG = np.copy(new_mean_NEG)\n        current_dist = np.copy(new_dist)\n\n        if np.sum([movement_POS, movement_NEG]) < 0.08:\n            current_vector = current_vector / current_dist\n            print(\"Found the \" + label + \" vector\")\n            break\n\n    return current_vector\n\n\ndef add_vector_to_images(data, vae, feature_vec):\n    n_to_show = 5\n    factors = [-4, -3, -2, -1, 0, 1, 2, 3, 4]\n\n    example_batch = list(data.take(1).get_single_element())\n    example_images = example_batch[0]\n\n    _, _, z_points = vae.encoder.predict(example_images, verbose=0)\n\n    fig = plt.figure(figsize=(18, 10))\n\n    counter = 1\n\n    for i in range(n_to_show):\n        img = example_images[i]\n        sub = fig.add_subplot(n_to_show, len(factors) + 1, counter)\n        sub.axis(\"off\")\n        sub.imshow(img)\n\n        counter += 1\n\n        for factor in factors:\n            changed_z_point = z_points[i] + feature_vec * factor\n            changed_image = vae.decoder.predict(\n                np.array([changed_z_point]), verbose=0\n            )[0]\n\n            sub = fig.add_subplot(n_to_show, len(factors) + 1, counter)\n            sub.axis(\"off\")\n            sub.imshow(changed_image)\n\n            counter += 1\n\n    plt.show()\n\n\ndef morph_faces(data, vae):\n    factors = np.arange(0, 1, 0.1)\n\n    example_batch = list(data.take(1).get_single_element())[:2]\n    example_images = example_batch[0]\n    _, _, z_points = vae.encoder.predict(example_images, verbose=0)\n\n    fig = plt.figure(figsize=(18, 8))\n\n    counter = 1\n\n    img = example_images[0]\n    sub = fig.add_subplot(1, len(factors) + 2, counter)\n    sub.axis(\"off\")\n    sub.imshow(img)\n\n    counter += 1\n\n    for factor in factors:\n        changed_z_point = z_points[0] * (1 - factor) + z_points[1] * factor\n        changed_image = vae.decoder.predict(\n            np.array([changed_z_point]), verbose=0\n        )[0]\n        sub = fig.add_subplot(1, len(factors) + 2, counter)\n        sub.axis(\"off\")\n        sub.imshow(changed_image)\n\n        counter += 1\n\n    img = example_images[1]\n    sub = fig.add_subplot(1, len(factors) + 2, counter)\n    sub.axis(\"off\")\n    sub.imshow(img)\n\n    plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-06-14T15:41:46.273449Z","iopub.execute_input":"2023-06-14T15:41:46.273747Z","iopub.status.idle":"2023-06-14T15:41:46.299612Z","shell.execute_reply.started":"2023-06-14T15:41:46.273703Z","shell.execute_reply":"2023-06-14T15:41:46.298296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%load_ext autoreload\n%autoreload 2\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras import (\n    layers,\n    models,\n    callbacks,\n    utils,\n    metrics,\n    losses,\n    optimizers,\n)\n\nfrom scipy.stats import norm\nimport pandas as pd\n\n# from kaggle.input.utils-file.utils import sample_batch, display\n\n# from vae_utils import get_vector_from_label, add_vector_to_images, morph_faces","metadata":{"execution":{"iopub.status.busy":"2023-06-14T15:41:46.301212Z","iopub.execute_input":"2023-06-14T15:41:46.301559Z","iopub.status.idle":"2023-06-14T15:42:02.412358Z","shell.execute_reply.started":"2023-06-14T15:41:46.301527Z","shell.execute_reply":"2023-06-14T15:42:02.411446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 0. Parameters <a name=\"parameters\"></a>","metadata":{}},{"cell_type":"code","source":"IMAGE_SIZE = 64\nCHANNELS = 3\nBATCH_SIZE = 128\nNUM_FEATURES = 64\nZ_DIM = 250\nLEARNING_RATE = 0.0005\nEPOCHS = 5\nBETA = 2000\nLOAD_MODEL = False","metadata":{"execution":{"iopub.status.busy":"2023-06-14T16:34:54.363479Z","iopub.execute_input":"2023-06-14T16:34:54.363885Z","iopub.status.idle":"2023-06-14T16:34:54.440773Z","shell.execute_reply.started":"2023-06-14T16:34:54.363852Z","shell.execute_reply":"2023-06-14T16:34:54.439875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1. Prepare the data <a name=\"prepare\"></a>","metadata":{}},{"cell_type":"code","source":"# Load the data\ntrain_data = utils.image_dataset_from_directory(\n    \"/kaggle/input/celeba-dataset/img_align_celeba\",\n    labels=None,\n    color_mode=\"rgb\",\n    image_size=(IMAGE_SIZE, IMAGE_SIZE),\n    batch_size=BATCH_SIZE,\n    shuffle=True,\n    seed=42,\n    interpolation=\"bilinear\",\n)","metadata":{"execution":{"iopub.status.busy":"2023-06-14T16:35:08.937096Z","iopub.execute_input":"2023-06-14T16:35:08.937455Z","iopub.status.idle":"2023-06-14T16:39:58.646850Z","shell.execute_reply.started":"2023-06-14T16:35:08.937420Z","shell.execute_reply":"2023-06-14T16:39:58.645758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Preprocess the data\ndef preprocess(img):\n    img = tf.cast(img, \"float32\") / 255.0\n    return img\n\n\ntrain = train_data.map(lambda x: preprocess(x))","metadata":{"execution":{"iopub.status.busy":"2023-06-14T16:39:58.648700Z","iopub.execute_input":"2023-06-14T16:39:58.649544Z","iopub.status.idle":"2023-06-14T16:39:58.772778Z","shell.execute_reply.started":"2023-06-14T16:39:58.649508Z","shell.execute_reply":"2023-06-14T16:39:58.771887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_sample = sample_batch(train)","metadata":{"execution":{"iopub.status.busy":"2023-06-14T16:39:58.773910Z","iopub.execute_input":"2023-06-14T16:39:58.774240Z","iopub.status.idle":"2023-06-14T16:39:59.855783Z","shell.execute_reply.started":"2023-06-14T16:39:58.774207Z","shell.execute_reply":"2023-06-14T16:39:59.854785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Show some faces from the training set\ndisplay(train_sample, cmap=None)","metadata":{"execution":{"iopub.status.busy":"2023-06-14T16:39:59.860357Z","iopub.execute_input":"2023-06-14T16:39:59.860698Z","iopub.status.idle":"2023-06-14T16:40:00.453586Z","shell.execute_reply.started":"2023-06-14T16:39:59.860669Z","shell.execute_reply":"2023-06-14T16:40:00.452635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Build the variational autoencoder <a name=\"build\"></a>","metadata":{"tags":[]}},{"cell_type":"code","source":"class Sampling(layers.Layer):\n    def call(self, inputs):\n        z_mean, z_log_var = inputs\n        batch = tf.shape(z_mean)[0]\n        dim = tf.shape(z_mean)[1]\n        epsilon = K.random_normal(shape=(batch, dim))\n        return z_mean + tf.exp(0.5 * z_log_var) * epsilon","metadata":{"execution":{"iopub.status.busy":"2023-06-14T16:40:00.455296Z","iopub.execute_input":"2023-06-14T16:40:00.455960Z","iopub.status.idle":"2023-06-14T16:40:00.532816Z","shell.execute_reply.started":"2023-06-14T16:40:00.455925Z","shell.execute_reply":"2023-06-14T16:40:00.531967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def encoder_module(IMAGE_SIZE=IMAGE_SIZE,NUM_FEATURES=NUM_FEATURES,Z_DIM=Z_DIM,strides=2,num_layers=5):\n    \n    # Encoder\n    encoder_input = layers.Input(\n        shape=(IMAGE_SIZE, IMAGE_SIZE, CHANNELS), name=\"encoder_input\"\n    )\n    x = layers.Conv2D(64, kernel_size=3, strides=2, padding=\"valid\")(\n        encoder_input\n    )\n    \n    x = layers.BatchNormalization()(x)\n    x = layers.LeakyReLU()(x)\n    \n    for i in range(num_layers):\n        \n\n        x = layers.Conv2D(NUM_FEATURES, kernel_size=3, strides=2, padding=\"same\")(x)\n        x = layers.BatchNormalization()(x)\n        x = layers.LeakyReLU()(x)\n       \n    shape_before_flattening = K.int_shape(x)[1:]  # the decoder will need this!\n\n    x = layers.Flatten()(x)\n    z_mean = layers.Dense(Z_DIM, name=\"z_mean\")(x)\n    z_log_var = layers.Dense(Z_DIM, name=\"z_log_var\")(x)\n    z = Sampling()([z_mean, z_log_var])\n\n    encoder = models.Model(encoder_input, [z_mean, z_log_var, z], name=\"encoder\")\n    print(encoder.summary())\n    return encoder,shape_before_flattening","metadata":{"execution":{"iopub.status.busy":"2023-06-14T16:40:00.534112Z","iopub.execute_input":"2023-06-14T16:40:00.534529Z","iopub.status.idle":"2023-06-14T16:40:00.615519Z","shell.execute_reply.started":"2023-06-14T16:40:00.534491Z","shell.execute_reply":"2023-06-14T16:40:00.614605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def decoder_module(shape_before_flattening,Z_DIM=Z_DIM,NUM_FEATURES=NUM_FEATURES,num_layers=5):\n    # Decoder\n    decoder_input = layers.Input(shape=(Z_DIM,), name=\"decoder_input\")\n    x = layers.Dense(np.prod(shape_before_flattening))(decoder_input)\n    x = layers.BatchNormalization()(x)\n    x = layers.LeakyReLU()(x)\n    x = layers.Reshape(shape_before_flattening)(x)\n   \n    for i in range(num_layers):\n        if i<num_layers-1:\n            \n            x = layers.Conv2DTranspose(\n                NUM_FEATURES, kernel_size=3, strides=2, padding=\"same\"\n            )(x)\n            x = layers.BatchNormalization()(x)\n            x = layers.LeakyReLU()(x)\n        else:\n            x = layers.Conv2DTranspose(\n                32, kernel_size=3, strides=2, padding=\"same\"\n            )(x)\n            x = layers.BatchNormalization()(x)\n            x = layers.LeakyReLU()(x)\n            \n   \n   \n    decoder_output = layers.Conv2DTranspose(\n        CHANNELS, kernel_size=3, strides=2, activation=\"sigmoid\", padding=\"same\"\n    )(x)\n    decoder = models.Model(decoder_input, decoder_output)\n    print(decoder.summary())\n    return decoder","metadata":{"execution":{"iopub.status.busy":"2023-06-14T16:40:00.617646Z","iopub.execute_input":"2023-06-14T16:40:00.618589Z","iopub.status.idle":"2023-06-14T16:40:00.694833Z","shell.execute_reply.started":"2023-06-14T16:40:00.618554Z","shell.execute_reply":"2023-06-14T16:40:00.694009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class VAE(models.Model):\n    def __init__(self, encoder, decoder, **kwargs):\n        super(VAE, self).__init__(**kwargs)\n        self.encoder = encoder\n        self.decoder = decoder\n        self.total_loss_tracker = metrics.Mean(name=\"total_loss\")\n        self.reconstruction_loss_tracker = metrics.Mean(\n            name=\"reconstruction_loss\"\n        )\n        self.kl_loss_tracker = metrics.Mean(name=\"kl_loss\")\n\n    @property\n    def metrics(self):\n        return [\n            self.total_loss_tracker,\n            self.reconstruction_loss_tracker,\n            self.kl_loss_tracker,\n        ]\n\n    def call(self, inputs):\n        \"\"\"Call the model on a particular input.\"\"\"\n        z_mean, z_log_var, z = encoder(inputs)\n        reconstruction = decoder(z)\n        return z_mean, z_log_var, reconstruction\n\n    def train_step(self, data):\n        \"\"\"Step run during training.\"\"\"\n        with tf.GradientTape() as tape:\n            z_mean, z_log_var, reconstruction = self(data, training=True)\n            reconstruction_loss = tf.reduce_mean(\n                BETA * losses.mean_squared_error(data, reconstruction)\n            )\n            kl_loss = tf.reduce_mean(\n                tf.reduce_sum(\n                    -0.5\n                    * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)),\n                    axis=1,\n                )\n            )\n            total_loss = reconstruction_loss + kl_loss\n\n        grads = tape.gradient(total_loss, self.trainable_weights)\n        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n\n        self.total_loss_tracker.update_state(total_loss)\n        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n        self.kl_loss_tracker.update_state(kl_loss)\n\n        return {\n            \"loss\": self.total_loss_tracker.result(),\n            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n            \"kl_loss\": self.kl_loss_tracker.result(),\n        }\n\n    def test_step(self, data):\n        \"\"\"Step run during validation.\"\"\"\n        if isinstance(data, tuple):\n            data = data[0]\n\n        z_mean, z_log_var, reconstruction = self(data)\n        reconstruction_loss = tf.reduce_mean(\n            BETA * losses.mean_squared_error(data, reconstruction)\n        )\n        kl_loss = tf.reduce_mean(\n            tf.reduce_sum(\n                -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)),\n                axis=1,\n            )\n        )\n        total_loss = reconstruction_loss + kl_loss\n\n        return {\n            \"loss\": total_loss,\n            \"reconstruction_loss\": reconstruction_loss,\n            \"kl_loss\": kl_loss,\n        }","metadata":{"execution":{"iopub.status.busy":"2023-06-14T16:40:00.696005Z","iopub.execute_input":"2023-06-14T16:40:00.696846Z","iopub.status.idle":"2023-06-14T16:40:00.778977Z","shell.execute_reply.started":"2023-06-14T16:40:00.696812Z","shell.execute_reply":"2023-06-14T16:40:00.778016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoder,shape_before_flattening=encoder_module(NUM_FEATURES=128,Z_DIM=250,strides=1,num_layers=5)","metadata":{"execution":{"iopub.status.busy":"2023-06-14T16:40:00.780825Z","iopub.execute_input":"2023-06-14T16:40:00.781612Z","iopub.status.idle":"2023-06-14T16:40:01.072212Z","shell.execute_reply.started":"2023-06-14T16:40:00.781579Z","shell.execute_reply":"2023-06-14T16:40:01.071488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"decoder=decoder_module(shape_before_flattening,Z_DIM=250,NUM_FEATURES=128)","metadata":{"execution":{"iopub.status.busy":"2023-06-14T16:40:01.075928Z","iopub.execute_input":"2023-06-14T16:40:01.076277Z","iopub.status.idle":"2023-06-14T16:40:01.587314Z","shell.execute_reply.started":"2023-06-14T16:40:01.076244Z","shell.execute_reply":"2023-06-14T16:40:01.586590Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a variational autoencoder\nvae = VAE(encoder, decoder)","metadata":{"execution":{"iopub.status.busy":"2023-06-14T16:40:01.588311Z","iopub.execute_input":"2023-06-14T16:40:01.588625Z","iopub.status.idle":"2023-06-14T16:40:01.792685Z","shell.execute_reply.started":"2023-06-14T16:40:01.588596Z","shell.execute_reply":"2023-06-14T16:40:01.791842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Train the variational autoencoder <a name=\"train\"></a>","metadata":{}},{"cell_type":"code","source":"# Compile the variational autoencoder\noptimizer = optimizers.Adam(learning_rate=LEARNING_RATE)\nvae.compile(optimizer=optimizer)","metadata":{"execution":{"iopub.status.busy":"2023-06-14T16:40:01.796833Z","iopub.execute_input":"2023-06-14T16:40:01.798958Z","iopub.status.idle":"2023-06-14T16:40:01.906410Z","shell.execute_reply.started":"2023-06-14T16:40:01.798921Z","shell.execute_reply":"2023-06-14T16:40:01.905598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a model save checkpoint\nmodel_checkpoint_callback = callbacks.ModelCheckpoint(\n    filepath=\"./checkpoint\",\n    save_weights_only=False,\n    save_freq=\"epoch\",\n    monitor=\"loss\",\n    mode=\"min\",\n    save_best_only=True,\n    verbose=0,\n)\n\ntensorboard_callback = callbacks.TensorBoard(log_dir=\"./logs\")\n\n\nclass ImageGenerator(callbacks.Callback):\n    def __init__(self, num_img, latent_dim):\n        self.num_img = num_img\n        self.latent_dim = latent_dim\n\n    def on_epoch_end(self, epoch, logs=None):\n        random_latent_vectors = tf.random.normal(\n            shape=(self.num_img, self.latent_dim)\n        )\n        generated_images = self.model.decoder(random_latent_vectors)\n        generated_images *= 255\n        generated_images.numpy()\n        for i in range(self.num_img):\n            img = utils.array_to_img(generated_images[i])\n            img.save(\"/kaggle/working/output/generated_img_%03d_%d.png\" % (epoch, i))","metadata":{"execution":{"iopub.status.busy":"2023-06-14T16:40:01.907538Z","iopub.execute_input":"2023-06-14T16:40:01.908049Z","iopub.status.idle":"2023-06-14T16:40:02.008074Z","shell.execute_reply.started":"2023-06-14T16:40:01.908013Z","shell.execute_reply":"2023-06-14T16:40:02.007312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nos.chdir('/kaggle/working/output/')","metadata":{"execution":{"iopub.status.busy":"2023-06-14T16:40:02.009504Z","iopub.execute_input":"2023-06-14T16:40:02.010257Z","iopub.status.idle":"2023-06-14T16:40:02.105772Z","shell.execute_reply.started":"2023-06-14T16:40:02.010212Z","shell.execute_reply":"2023-06-14T16:40:02.105013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir output","metadata":{"execution":{"iopub.status.busy":"2023-06-14T16:44:49.528756Z","iopub.execute_input":"2023-06-14T16:44:49.529422Z","iopub.status.idle":"2023-06-14T16:44:50.639070Z","shell.execute_reply.started":"2023-06-14T16:44:49.529387Z","shell.execute_reply":"2023-06-14T16:44:50.637775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Load old weights if required\nif LOAD_MODEL:\n    vae.load_weights(\"./models/vae\")\n    tmp = vae.predict(train.take(1))","metadata":{"execution":{"iopub.status.busy":"2023-06-14T16:40:02.211392Z","iopub.execute_input":"2023-06-14T16:40:02.212319Z","iopub.status.idle":"2023-06-14T16:40:02.306492Z","shell.execute_reply.started":"2023-06-14T16:40:02.212285Z","shell.execute_reply":"2023-06-14T16:40:02.305762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vae.fit(\n    train,\n    epochs=EPOCHS,\n    callbacks=[\n        model_checkpoint_callback,\n        tensorboard_callback,\n        ImageGenerator(num_img=10, latent_dim=Z_DIM),\n    ],\n)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-06-14T16:45:41.809865Z","iopub.execute_input":"2023-06-14T16:45:41.811011Z","iopub.status.idle":"2023-06-14T17:13:35.610160Z","shell.execute_reply.started":"2023-06-14T16:45:41.810958Z","shell.execute_reply":"2023-06-14T17:13:35.609275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save the final models\nvae.save(\"./models/vae\")\nencoder.save(\"./models/encoder\")\ndecoder.save(\"./models/decoder\")","metadata":{"execution":{"iopub.status.busy":"2023-06-14T17:17:19.327831Z","iopub.execute_input":"2023-06-14T17:17:19.328200Z","iopub.status.idle":"2023-06-14T17:17:33.613216Z","shell.execute_reply.started":"2023-06-14T17:17:19.328171Z","shell.execute_reply":"2023-06-14T17:17:33.612287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Reconstruct using the variational autoencoder <a name=\"reconstruct\"></a>","metadata":{}},{"cell_type":"code","source":"# Select a subset of the test set\nbatches_to_predict = 1\nexample_images = np.array(\n    list(train.take(batches_to_predict).get_single_element())\n)","metadata":{"execution":{"iopub.status.busy":"2023-06-14T17:18:21.916826Z","iopub.execute_input":"2023-06-14T17:18:21.917463Z","iopub.status.idle":"2023-06-14T17:18:23.718526Z","shell.execute_reply.started":"2023-06-14T17:18:21.917427Z","shell.execute_reply":"2023-06-14T17:18:23.717548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create autoencoder predictions and display\nz_mean, z_log_var, reconstructions = vae.predict(example_images)\nprint(\"Example real faces\")\ndisplay(example_images)\nprint(\"Reconstructions\")\ndisplay(reconstructions)","metadata":{"execution":{"iopub.status.busy":"2023-06-14T17:18:24.611911Z","iopub.execute_input":"2023-06-14T17:18:24.612262Z","iopub.status.idle":"2023-06-14T17:18:26.832956Z","shell.execute_reply.started":"2023-06-14T17:18:24.612233Z","shell.execute_reply":"2023-06-14T17:18:26.831919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4. Latent space distribution","metadata":{}},{"cell_type":"code","source":"_, _, z = vae.encoder.predict(example_images)\n\nx = np.linspace(-3, 3, 100)\n\nfig = plt.figure(figsize=(20, 5))\nfig.subplots_adjust(hspace=0.6, wspace=0.4)\n\nfor i in range(50):\n    ax = fig.add_subplot(5, 10, i + 1)\n    ax.hist(z[:, i], density=True, bins=20)\n    ax.axis(\"off\")\n    ax.text(\n        0.5, -0.35, str(i), fontsize=10, ha=\"center\", transform=ax.transAxes\n    )\n    ax.plot(x, norm.pdf(x))\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-06-14T17:18:26.834970Z","iopub.execute_input":"2023-06-14T17:18:26.835954Z","iopub.status.idle":"2023-06-14T17:18:31.023705Z","shell.execute_reply.started":"2023-06-14T17:18:26.835918Z","shell.execute_reply":"2023-06-14T17:18:31.022709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5. Generate new faces <a name=\"decode\"></a>","metadata":{}},{"cell_type":"code","source":"# Sample some points in the latent space, from the standard normal distribution\ngrid_width, grid_height = (10, 3)\nz_sample = np.random.normal(size=(grid_width * grid_height, Z_DIM))","metadata":{"execution":{"iopub.status.busy":"2023-06-14T17:18:31.030782Z","iopub.execute_input":"2023-06-14T17:18:31.034020Z","iopub.status.idle":"2023-06-14T17:18:31.139394Z","shell.execute_reply.started":"2023-06-14T17:18:31.033980Z","shell.execute_reply":"2023-06-14T17:18:31.138164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Decode the sampled points\nreconstructions = decoder.predict(z_sample)","metadata":{"execution":{"iopub.status.busy":"2023-06-14T17:18:31.141226Z","iopub.execute_input":"2023-06-14T17:18:31.141925Z","iopub.status.idle":"2023-06-14T17:18:31.965684Z","shell.execute_reply.started":"2023-06-14T17:18:31.141885Z","shell.execute_reply":"2023-06-14T17:18:31.964719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Draw a plot of decoded images\nfig = plt.figure(figsize=(18, 5))\nfig.subplots_adjust(hspace=0.4, wspace=0.4)\n\n# Output the grid of faces\nfor i in range(grid_width * grid_height):\n    ax = fig.add_subplot(grid_height, grid_width, i + 1)\n    ax.axis(\"off\")\n    ax.imshow(reconstructions[i, :, :])","metadata":{"execution":{"iopub.status.busy":"2023-06-14T17:18:31.968267Z","iopub.execute_input":"2023-06-14T17:18:31.968860Z","iopub.status.idle":"2023-06-14T17:18:33.362815Z","shell.execute_reply.started":"2023-06-14T17:18:31.968823Z","shell.execute_reply":"2023-06-14T17:18:33.361710Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 6. Manipulate the images <a name=\"manipulate\"></a>","metadata":{}},{"cell_type":"code","source":"# Load the label dataset\nattributes = pd.read_csv(\"/kaggle/input/celeba-dataset/list_attr_celeba.csv\")\nprint(attributes.columns)\nattributes.head()","metadata":{"execution":{"iopub.status.busy":"2023-06-14T17:18:33.364501Z","iopub.execute_input":"2023-06-14T17:18:33.365543Z","iopub.status.idle":"2023-06-14T17:18:34.648826Z","shell.execute_reply.started":"2023-06-14T17:18:33.365505Z","shell.execute_reply":"2023-06-14T17:18:34.647802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the face data with label attached\nLABEL = \"Blond_Hair\"  # <- Set this label\nlabelled_test = utils.image_dataset_from_directory(\n    \"/kaggle/input/celeba-dataset/img_align_celeba\",\n    labels=attributes[LABEL].tolist(),\n    color_mode=\"rgb\",\n    image_size=(IMAGE_SIZE, IMAGE_SIZE),\n    batch_size=BATCH_SIZE,\n    shuffle=True,\n    seed=42,\n    validation_split=0.2,\n    subset=\"validation\",\n    interpolation=\"bilinear\",\n)\n\nlabelled = labelled_test.map(lambda x, y: (preprocess(x), y))","metadata":{"execution":{"iopub.status.busy":"2023-06-14T17:18:34.650130Z","iopub.execute_input":"2023-06-14T17:18:34.650564Z","iopub.status.idle":"2023-06-14T17:26:02.703691Z","shell.execute_reply.started":"2023-06-14T17:18:34.650531Z","shell.execute_reply":"2023-06-14T17:26:02.702764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2023-06-14T18:07:13.465388Z","iopub.execute_input":"2023-06-14T18:07:13.465798Z","iopub.status.idle":"2023-06-14T18:07:13.549882Z","shell.execute_reply.started":"2023-06-14T18:07:13.465764Z","shell.execute_reply":"2023-06-14T18:07:13.548915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LABEL","metadata":{"execution":{"iopub.status.busy":"2023-06-14T18:08:59.087256Z","iopub.execute_input":"2023-06-14T18:08:59.087639Z","iopub.status.idle":"2023-06-14T18:08:59.167812Z","shell.execute_reply.started":"2023-06-14T18:08:59.087610Z","shell.execute_reply":"2023-06-14T18:08:59.166699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# labelled\n# list(labelled.take(1).get_single_element())","metadata":{"execution":{"iopub.status.busy":"2023-06-14T18:08:49.955139Z","iopub.execute_input":"2023-06-14T18:08:49.955523Z","iopub.status.idle":"2023-06-14T18:08:50.032697Z","shell.execute_reply.started":"2023-06-14T18:08:49.955494Z","shell.execute_reply":"2023-06-14T18:08:50.031783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Find the attribute vector\nattribute_vec = get_vector_from_label(labelled, vae, Z_DIM, LABEL)","metadata":{"execution":{"iopub.status.busy":"2023-06-14T17:26:52.202148Z","iopub.execute_input":"2023-06-14T17:26:52.202917Z","iopub.status.idle":"2023-06-14T17:28:02.543477Z","shell.execute_reply.started":"2023-06-14T17:26:52.202875Z","shell.execute_reply":"2023-06-14T17:28:02.542407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Add vector to images\nadd_vector_to_images(labelled, vae, attribute_vec)","metadata":{"execution":{"iopub.status.busy":"2023-06-14T17:28:02.545014Z","iopub.execute_input":"2023-06-14T17:28:02.545360Z","iopub.status.idle":"2023-06-14T17:28:08.396803Z","shell.execute_reply.started":"2023-06-14T17:28:02.545327Z","shell.execute_reply":"2023-06-14T17:28:08.395963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"morph_faces(labelled, vae)add_vector_to_images","metadata":{"execution":{"iopub.status.busy":"2023-06-14T17:28:08.398186Z","iopub.execute_input":"2023-06-14T17:28:08.405920Z","iopub.status.idle":"2023-06-14T17:28:08.484926Z","shell.execute_reply.started":"2023-06-14T17:28:08.405882Z","shell.execute_reply":"2023-06-14T17:28:08.483771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}